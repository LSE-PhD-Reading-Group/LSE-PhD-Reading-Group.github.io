# Doubly Inhomogeneous Reinforcement Learning

This paper studies reinforcement learning (RL) in doubly inhomogeneous environments under temporal non stationarity and subject heterogeneity. In a number of applications, it is commonplace to encounter datasets generated by system dynamics that may change over time and population, challenging high-quality sequential decision making. Nonetheless, most existing RL solutions require either temporal stationarity or subject homogeneity, which would result in sub-optimal policies if both assumptions were violated. 

To address both challenges simultaneously, we propose an original algorithm to determine the “best data chunks” that display similar dynamics over time and across individuals for policy learning, which alternates between most recent change point detection and cluster identification. 

**Paper:** Hu, Liyuan, et al. "Doubly Inhomogeneous Reinforcement Learning." [arXiv:2211.03983v2](https://arxiv.org/pdf/2211.03983.pdf)
